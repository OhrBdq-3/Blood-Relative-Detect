{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T08:01:15.693581Z","iopub.execute_input":"2024-08-13T08:01:15.693936Z","iopub.status.idle":"2024-08-13T08:01:16.616902Z","shell.execute_reply.started":"2024-08-13T08:01:15.693907Z","shell.execute_reply":"2024-08-13T08:01:16.616010Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain_path = '/kaggle/input/nlp-getting-started/train.csv'\ndf = pd.read_csv(train_path)\ndisaster=df[df['target']==1]['target'].value_counts()\nnon_disaster=df[df['target']==0]['target'].value_counts()\nprint(f'disaster count: {disaster}')\nprint(f'non_disaster count: {non_disaster}')\ndf['label'] = df['target']","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:16.618610Z","iopub.execute_input":"2024-08-13T08:01:16.619330Z","iopub.status.idle":"2024-08-13T08:01:16.682875Z","shell.execute_reply.started":"2024-08-13T08:01:16.619297Z","shell.execute_reply":"2024-08-13T08:01:16.682047Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"disaster count: target\n1    3271\nName: count, dtype: int64\nnon_disaster count: target\n0    4342\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:16.683791Z","iopub.execute_input":"2024-08-13T08:01:16.684063Z","iopub.status.idle":"2024-08-13T08:01:16.697911Z","shell.execute_reply.started":"2024-08-13T08:01:16.684031Z","shell.execute_reply":"2024-08-13T08:01:16.696940Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  label  \n0       1      1  \n1       1      1  \n2       1      1  \n3       1      1  \n4       1      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\ndata = Dataset.from_pandas(df[['text','label']])\ndata","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:16.699942Z","iopub.execute_input":"2024-08-13T08:01:16.700281Z","iopub.status.idle":"2024-08-13T08:01:17.904149Z","shell.execute_reply.started":"2024-08-13T08:01:16.700258Z","shell.execute_reply":"2024-08-13T08:01:17.903205Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 7613\n})"},"metadata":{}}]},{"cell_type":"code","source":"data[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:17.905351Z","iopub.execute_input":"2024-08-13T08:01:17.905855Z","iopub.status.idle":"2024-08-13T08:01:17.913776Z","shell.execute_reply.started":"2024-08-13T08:01:17.905820Z","shell.execute_reply":"2024-08-13T08:01:17.912911Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'text': 'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n 'label': 1}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer,AutoModelForSequenceClassification\nimport torch\n\nmodel_name_or_path = \"Qwen/Qwen2-1.5B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name_or_path,device_map='auto',torch_dtype=torch.bfloat16,num_labels=2)\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:17.914823Z","iopub.execute_input":"2024-08-13T08:01:17.915132Z","iopub.status.idle":"2024-08-13T08:01:39.704960Z","shell.execute_reply.started":"2024-08-13T08:01:17.915110Z","shell.execute_reply":"2024-08-13T08:01:39.704052Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15220df2f0e9418f95fef5e0ea9c0ee7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b8c83b5a4b4d30808505dcf723be9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a242c2c70d64135928f31d0d16ec72b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70372a52b952494089f64c2f9d5e9159"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87a6a7c032d74d39826202330f82aa01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161fe6aed8e041eb836a18c8e78d73fa"}},"metadata":{}},{"name":"stderr","text":"Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2-1.5B-Instruct and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:39.706081Z","iopub.execute_input":"2024-08-13T08:01:39.706530Z","iopub.status.idle":"2024-08-13T08:01:57.571590Z","shell.execute_reply.started":"2024-08-13T08:01:39.706504Z","shell.execute_reply":"2024-08-13T08:01:57.570452Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting peft\n  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.32.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.23.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m318.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import TaskType,get_peft_model,LoraConfig\nlora_config = LoraConfig(\n    task_type = TaskType.SEQ_CLS,\n    r = 8,\n    target_modules = [\"q_proj\", \"k_proj\"]\n)\nmodel = get_peft_model(model,lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:57.575365Z","iopub.execute_input":"2024-08-13T08:01:57.575684Z","iopub.status.idle":"2024-08-13T08:01:57.766952Z","shell.execute_reply.started":"2024-08-13T08:01:57.575658Z","shell.execute_reply":"2024-08-13T08:01:57.766229Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.config.pad_token_id = tokenizer.eos_token_id\nmodel.config.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:57.768187Z","iopub.execute_input":"2024-08-13T08:01:57.768788Z","iopub.status.idle":"2024-08-13T08:01:57.775239Z","shell.execute_reply.started":"2024-08-13T08:01:57.768757Z","shell.execute_reply":"2024-08-13T08:01:57.774315Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"151645"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:57.777975Z","iopub.execute_input":"2024-08-13T08:01:57.778249Z","iopub.status.idle":"2024-08-13T08:01:57.786821Z","shell.execute_reply.started":"2024-08-13T08:01:57.778227Z","shell.execute_reply":"2024-08-13T08:01:57.785963Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"7613"},"metadata":{}}]},{"cell_type":"code","source":"dataset = data.train_test_split(test_size=0.2)\ndef preprocess_func(examples):\n    return tokenizer(examples['text'],truncation=True,padding=True,return_tensors=\"pt\")\nencoded_dataset = dataset.map(preprocess_func,batched=True,batch_size=len(df))\nencoded_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:57.787804Z","iopub.execute_input":"2024-08-13T08:01:57.788082Z","iopub.status.idle":"2024-08-13T08:01:59.152495Z","shell.execute_reply.started":"2024-08-13T08:01:57.788059Z","shell.execute_reply":"2024-08-13T08:01:59.151598Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6090 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7215caf639074ec6b0b3db702c939199"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1523 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"544d599ca248499a9f6075dc58465b52"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 6090\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 1523\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer\nnum_train_epochs = 1\nper_device_train_batch_size = 4\nper_device_eval_batch_size = 4\nwarmup_steps = 10\nweight_decay = 0.01\nlogging_steps = 1\nsave_path = '/output'\ntraining_args = TrainingArguments(\n    output_dir = save_path,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size = per_device_train_batch_size,\n    per_device_eval_batch_size = per_device_eval_batch_size,\n    warmup_steps = warmup_steps,\n    weight_decay = weight_decay,\n    logging_steps = logging_steps,\n    gradient_accumulation_steps = 16,\n    use_cpu=False,\n    report_to=\"none\"\n)\ntrainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset=encoded_dataset['train'],\n    eval_dataset = encoded_dataset['test']\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:01:59.153631Z","iopub.execute_input":"2024-08-13T08:01:59.153889Z","iopub.status.idle":"2024-08-13T08:23:08.852670Z","shell.execute_reply.started":"2024-08-13T08:01:59.153866Z","shell.execute_reply":"2024-08-13T08:23:08.851660Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2024-08-13 08:02:01.095491: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-13 08:02:01.095619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-13 08:02:01.225053: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nWe detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [95/95 20:43, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.933600</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2.256300</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2.109900</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2.315200</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>2.364700</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>2.125700</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>2.185900</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>2.551800</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>2.021300</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.032400</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.815800</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.345600</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.083900</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.146400</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.867300</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.349900</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.454700</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.820100</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>2.096900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.349900</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.868800</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.504000</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2.382300</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>2.097500</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>2.169200</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2.539000</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>1.447800</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>1.995600</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.543600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.268600</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>1.891800</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.996800</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>2.051500</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>1.679000</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>2.234100</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>2.027300</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>2.013200</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>2.292300</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.605100</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.887500</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>1.523500</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.534300</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>2.195800</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.745700</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>1.441400</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.613800</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.621500</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>2.141800</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>1.934600</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.663700</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>2.001000</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>1.396300</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>2.058300</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>2.060700</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.442400</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>2.090400</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.818100</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.984100</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.642500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.135600</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.840800</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>1.342700</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>2.046900</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.691500</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.484400</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>2.225000</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.509800</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.526900</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>2.167100</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.796100</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>1.584900</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>1.467300</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>1.535800</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>1.433200</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>2.056400</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>1.867800</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>2.376100</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>1.327800</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>1.407800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.529800</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>1.774800</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>1.398700</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>2.309400</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>1.625700</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>2.421400</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>1.855900</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>2.037500</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>2.011500</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>1.489900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.490100</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>1.335900</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>2.087300</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>1.370800</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>1.764900</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>2.002500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=95, training_loss=1.8838090093512283, metrics={'train_runtime': 1256.2491, 'train_samples_per_second': 4.848, 'train_steps_per_second': 0.076, 'total_flos': 3970819250257920.0, 'train_loss': 1.8838090093512283, 'epoch': 0.9980302035456337})"},"metadata":{}}]},{"cell_type":"code","source":"test_path = '/kaggle/input/nlp-getting-started/test.csv'\ndf_test = pd.read_csv(test_path)\ndf_test_samples = df_test['text'].sample(10)\ndf_test_samples","metadata":{"execution":{"iopub.status.busy":"2024-08-13T08:23:08.854001Z","iopub.execute_input":"2024-08-13T08:23:08.854694Z","iopub.status.idle":"2024-08-13T08:23:08.887523Z","shell.execute_reply.started":"2024-08-13T08:23:08.854656Z","shell.execute_reply":"2024-08-13T08:23:08.886733Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"2406    Refugees as citizens - The Hindu http://t.co/G...\n134     @5SOStag honestly he could say an apocalypse i...\n411     If you bored as shit don't nobody fuck wit you...\n203     @RealTwanBrown Yesterday I Had A Heat Attack ?...\n889     The Devil Wears Prada is still one of my favou...\n1432    my father fucking died when the north tower co...\n3024    Oh itÛªs a soccer ball? I thought it was the ...\n2741    #Bestnaijamade: 16yr old PKK suicide bomber wh...\n463        @ComplexMag he asking for a body bags @PUSHA_T\n291     @JuneSnowpaw Yeah Gimme dat creamy white stuff ;3\nName: text, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"for x in df_test_samples:\n    inputs_ids = tokenizer([x],return_tensors=\"pt\").to(model.device)\n    outputs = model(**inputs_ids)\n    predicted = outputs.logits.argmax(dim=-1).cpu().numpy().tolist()\n    print(predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}